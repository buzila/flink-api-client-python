# swagger-client
No description provided (generated by Swagger Codegen https://github.com/swagger-api/swagger-codegen)

This Python package is automatically generated by the [Swagger Codegen](https://github.com/swagger-api/swagger-codegen) project:

- API version: 1.0.0
- Package version: 1.0.0
- Build package: io.swagger.codegen.v3.generators.python.PythonClientCodegen

## Requirements.

Python 2.7 and 3.4+

## Installation & Usage
### pip install

If the python package is hosted on Github, you can install directly from Github

```sh
pip install git+https://github.com/GIT_USER_ID/GIT_REPO_ID.git
```
(you may need to run `pip` with root permission: `sudo pip install git+https://github.com/GIT_USER_ID/GIT_REPO_ID.git`)

Then import the package:
```python
import swagger_client 
```

### Setuptools

Install via [Setuptools](http://pypi.python.org/pypi/setuptools).

```sh
python setup.py install --user
```
(or `sudo python setup.py install` to install the package for all users)

Then import the package:
```python
import swagger_client
```

## Getting Started

Please follow the [installation procedure](#installation--usage) and then run the following:

```python
from __future__ import print_function
import time
import swagger_client
from swagger_client.rest import ApiException
from pprint import pprint

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
body = swagger_client.SavepointTriggerRequestBody() # SavepointTriggerRequestBody | 
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job

try:
    # Triggers a savepoint, and optionally cancels the job afterwards
    api_response = api_instance.create_job_savepoint(body, jobid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->create_job_savepoint: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jarid = 'jarid_example' # str | String value that identifies a jar. When uploading the jar a path is returned, where the filename is the ID. This value is equivalent to the `id` field in the list of uploaded jars (/jars)

try:
    # Deletes a jar previously uploaded via '/jars/upload'
    api_instance.delete_jar(jarid)
except ApiException as e:
    print("Exception when calling FlinkApi->delete_jar: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
include_serialized_value = true # bool | Boolean value that specifies whether serialized user task accumulators should be included in the response (optional)

try:
    # Returns the accumulators for all tasks of a job, aggregated across the respective subtasks
    api_response = api_instance.get_job_accumulators(jobid, include_serialized_value=include_serialized_value)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_accumulators: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
vertexid = 'vertexid_example' # str | 32-character hexadecimal string value that identifies a job vertex
get = 'get_example' # str | Comma-separated list of string values to select specific metrics (optional)
agg = 'agg_example' # str | Comma-separated list of aggregation modes which should be calculated. Available aggregations are: \"min, max, sum, avg\" (optional)
subtasks = 'subtasks_example' # str | Comma-separated list of integer ranges (e.g. \"1,3,5-9\") to select specific subtasks (optional)

try:
    # Provides access to aggregated subtask metrics
    api_response = api_instance.get_job_aggregated_subtask_metrics(jobid, vertexid, get=get, agg=agg, subtasks=subtasks)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_aggregated_subtask_metrics: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
checkpointid = 56 # int | Long value that identifies a checkpoint

try:
    # Returns details for a checkpoint
    api_response = api_instance.get_job_checkpoint_details(jobid, checkpointid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_checkpoint_details: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
checkpointid = 56 # int | Long value that identifies a checkpoint
vertexid = 'vertexid_example' # str | 32-character hexadecimal string value that identifies a job vertex

try:
    # Returns checkpoint statistics for a task and its subtasks
    api_response = api_instance.get_job_checkpoint_statistics(jobid, checkpointid, vertexid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_checkpoint_statistics: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job

try:
    # Returns checkpointing statistics for a job
    api_response = api_instance.get_job_checkpoints(jobid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_checkpoints: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job

try:
    # Returns the checkpointing configuration
    api_response = api_instance.get_job_checkpoints_config(jobid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_checkpoints_config: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job

try:
    # Returns the configuration of a job
    api_response = api_instance.get_job_config(jobid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_config: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job

try:
    # Returns details of a job
    api_response = api_instance.get_job_details(jobid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_details: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job

try:
    # Returns the non-recoverable exceptions that have been observed by the job. The truncated flag defines whether more exceptions occurred, but are not listed, because the response would otherwise get too big
    api_response = api_instance.get_job_exceptions(jobid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_exceptions: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
get = 'get_example' # str | Comma-separated list of string values to select specific metrics (optional)

try:
    # Provides access to job manager metrics
    api_response = api_instance.get_job_manager_metrics(get=get)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_manager_metrics: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
get = 'get_example' # str | Comma-separated list of string values to select specific metrics (optional)

try:
    # Provides access to job metrics
    api_response = api_instance.get_job_metrics(jobid, get=get)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_metrics: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job

try:
    # Returns the dataflow plan of a job
    api_response = api_instance.get_job_plan(jobid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_plan: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
triggerid = 'triggerid_example' # str | 32-character hexadecimal string that identifies an asynchronous operation trigger ID. The ID was returned then the operation was triggered

try:
    # Returns the status of a rescaling operation
    api_response = api_instance.get_job_rescaling_status(jobid, triggerid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_rescaling_status: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job

try:
    # Returns the result of a job execution. Gives access to the execution time of the job and to all accumulators created by this job
    api_response = api_instance.get_job_result(jobid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_result: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
triggerid = 'triggerid_example' # str | 32-character hexadecimal string that identifies an asynchronous operation trigger ID. The ID was returned then the operation was triggered

try:
    # Returns the status of a savepoint operation
    api_response = api_instance.get_job_savepoint_status(jobid, triggerid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_savepoint_status: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
vertexid = 'vertexid_example' # str | 32-character hexadecimal string value that identifies a job vertex

try:
    # Returns all user-defined accumulators for all subtasks of a task
    api_response = api_instance.get_job_subtask_accumulators(jobid, vertexid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_subtask_accumulators: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
vertexid = 'vertexid_example' # str | 32-character hexadecimal string value that identifies a job vertex
subtaskindex = 56 # int | Positive integer value that identifies a subtask
attempt = 56 # int | Positive integer value that identifies an execution attempt

try:
    # Returns the accumulators of an execution attempt of a subtask. Multiple execution attempts happen in case of failure/recovery
    api_response = api_instance.get_job_subtask_attempt_accumulators(jobid, vertexid, subtaskindex, attempt)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_subtask_attempt_accumulators: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
vertexid = 'vertexid_example' # str | 32-character hexadecimal string value that identifies a job vertex
subtaskindex = 56 # int | Positive integer value that identifies a subtask
attempt = 56 # int | Positive integer value that identifies an execution attempt

try:
    # Returns details of an execution attempt of a subtask. Multiple execution attempts happen in case of failure/recovery
    api_response = api_instance.get_job_subtask_attempt_details(jobid, vertexid, subtaskindex, attempt)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_subtask_attempt_details: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
vertexid = 'vertexid_example' # str | 32-character hexadecimal string value that identifies a job vertex
subtaskindex = 56 # int | Positive integer value that identifies a subtask

try:
    # Returns details of the current or latest execution attempt of a subtask
    api_response = api_instance.get_job_subtask_details(jobid, vertexid, subtaskindex)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_subtask_details: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
vertexid = 'vertexid_example' # str | 32-character hexadecimal string value that identifies a job vertex
subtaskindex = 56 # int | Positive integer value that identifies a subtask
get = 'get_example' # str | Comma-separated list of string values to select specific metrics (optional)

try:
    # Provides access to subtask metrics
    api_response = api_instance.get_job_subtask_metrics(jobid, vertexid, subtaskindex, get=get)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_subtask_metrics: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
vertexid = 'vertexid_example' # str | 32-character hexadecimal string value that identifies a job vertex

try:
    # Returns time-related information for all subtasks of a task
    api_response = api_instance.get_job_subtask_times(jobid, vertexid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_subtask_times: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
vertexid = 'vertexid_example' # str | 32-character hexadecimal string value that identifies a job vertex

try:
    # Returns user-defined accumulators of a task, aggregated across all subtasks
    api_response = api_instance.get_job_task_accumulators(jobid, vertexid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_task_accumulators: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
vertexid = 'vertexid_example' # str | 32-character hexadecimal string value that identifies a job vertex

try:
    # Returns back-pressure information for a job, and may initiate back-pressure sampling if necessary
    api_response = api_instance.get_job_task_backpressure(jobid, vertexid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_task_backpressure: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
vertexid = 'vertexid_example' # str | 32-character hexadecimal string value that identifies a job vertex

try:
    # Returns details for a task, with a summary for each of its subtasks
    api_response = api_instance.get_job_task_details(jobid, vertexid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_task_details: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
vertexid = 'vertexid_example' # str | 32-character hexadecimal string value that identifies a job vertex

try:
    # Returns task information aggregated by task manager
    api_response = api_instance.get_job_task_details_by_task_manager(jobid, vertexid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_task_details_by_task_manager: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
vertexid = 'vertexid_example' # str | 32-character hexadecimal string value that identifies a job vertex
get = 'get_example' # str | Comma-separated list of string values to select specific metrics (optional)

try:
    # Provides access to task metrics
    api_response = api_instance.get_job_task_metrics(jobid, vertexid, get=get)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_job_task_metrics: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))

try:
    # Returns an overview over all jobs and their current state
    api_response = api_instance.get_jobs()
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_jobs: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
get = 'get_example' # str | Comma-separated list of string values to select specific metrics (optional)
agg = 'agg_example' # str | Comma-separated list of aggregation modes which should be calculated. Available aggregations are: \"min, max, sum, avg\" (optional)
jobs = 'jobs_example' # str | Comma-separated list of 32-character hexadecimal strings to select specific jobs (optional)

try:
    # Provides access to aggregated job metrics
    api_response = api_instance.get_jobs_metrics(get=get, agg=agg, jobs=jobs)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_jobs_metrics: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))

try:
    # Returns an overview over all jobs
    api_response = api_instance.get_jobs_overview()
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_jobs_overview: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))

try:
    # Returns an overview over the Flink cluster
    api_response = api_instance.get_overview()
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_overview: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
triggerid = 'triggerid_example' # str | 32-character hexadecimal string that identifies an asynchronous operation trigger ID. The ID was returned then the operation was triggered

try:
    # Returns the status of a savepoint disposal operation
    api_response = api_instance.get_savepoint_disposal_status(triggerid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_savepoint_disposal_status: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
get = 'get_example' # str | Comma-separated list of string values to select specific metrics (optional)
agg = 'agg_example' # str | Comma-separated list of aggregation modes which should be calculated. Available aggregations are: \"min, max, sum, avg\" (optional)
taskmanagers = 'taskmanagers_example' # str | Comma-separated list of 32-character hexadecimal strings to select specific task managers (optional)

try:
    # Provides access to aggregated task manager metrics
    api_response = api_instance.get_task_manager_aggregated_metrics(get=get, agg=agg, taskmanagers=taskmanagers)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_task_manager_aggregated_metrics: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
taskmanagerid = 'taskmanagerid_example' # str | 32-character hexadecimal string that identifies a task manager

try:
    # Returns details for a task manager
    api_response = api_instance.get_task_manager_details(taskmanagerid)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_task_manager_details: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
taskmanagerid = 'taskmanagerid_example' # str | 32-character hexadecimal string that identifies a task manager
get = 'get_example' # str | Comma-separated list of string values to select specific metrics (optional)

try:
    # Provides access to task manager metrics
    api_response = api_instance.get_task_manager_metrics(taskmanagerid, get=get)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_task_manager_metrics: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))

try:
    # Returns an overview over all task managers
    api_response = api_instance.get_task_managers_overview()
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->get_task_managers_overview: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))

try:
    # Returns a list of all jars previously uploaded via '/jars/upload'
    api_response = api_instance.list_jars()
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->list_jars: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jarid = 'jarid_example' # str | String value that identifies a jar. When uploading the jar a path is returned, where the filename is the ID. This value is equivalent to the `id` field in the list of uploaded jars (/jars)
allow_non_restored_state = true # bool | Boolean value that specifies whether the job submission should be rejected if the savepoint contains state that cannot be mapped back to the job (optional)
savepoint_path = 'savepoint_path_example' # str | Comma-separated list of program arguments (optional)
program_args = 'program_args_example' # str | Deprecated, please use 'programArg' instead. String value that specifies the arguments for the program or plan (optional)
program_arg = 'program_arg_example' # str | Comma-separated list of program arguments (optional)
entry_class = 'entry_class_example' # str | String value that specifies the fully qualified name of the entry point class. Overrides the class defined in the jar file manifest (optional)
parallelism = 56 # int | Positive integer value that specifies the desired parallelism for the job (optional)

try:
    # Submits a job by running a jar previously uploaded via '/jars/upload'. Program arguments can be passed both via the JSON request (recommended) or query parameters
    api_response = api_instance.run_jar(jarid, allow_non_restored_state=allow_non_restored_state, savepoint_path=savepoint_path, program_args=program_args, program_arg=program_arg, entry_class=entry_class, parallelism=parallelism)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->run_jar: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))

try:
    # Returns the configuration of the WebUI
    api_response = api_instance.show_config()
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->show_config: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))

try:
    # Returns the cluster configuration
    api_response = api_instance.show_job_manager_config()
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->show_job_manager_config: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jarid = 'jarid_example' # str | String value that identifies a jar. When uploading the jar a path is returned, where the filename is the ID. This value is equivalent to the `id` field in the list of uploaded jars (/jars)
program_args = 'program_args_example' # str | Deprecated, please use 'programArg' instead. String value that specifies the arguments for the program or plan (optional)
program_arg = 'program_arg_example' # str | Comma-separated list of program arguments (optional)
entry_class = 'entry_class_example' # str | String value that specifies the fully qualified name of the entry point class. Overrides the class defined in the jar file manifest (optional)
parallelism = 56 # int | Positive integer value that specifies the desired parallelism for the job (optional)

try:
    # Returns the dataflow plan of a job contained in a jar previously uploaded via '/jars/upload'. Program arguments can be passed both via the JSON request (recommended) or query parameters
    api_response = api_instance.show_plan(jarid, program_args=program_args, program_arg=program_arg, entry_class=entry_class, parallelism=parallelism)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->show_plan: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))

try:
    # Shuts-down the cluster
    api_instance.shutdown_cluster()
except ApiException as e:
    print("Exception when calling FlinkApi->shutdown_cluster: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
job_graph_file_name = 'job_graph_file_name_example' # str | 
job_jar_file_names = ['job_jar_file_names_example'] # list[str] | 
job_artifact_file_names = [swagger_client.JobsJobArtifactFileNames()] # list[JobsJobArtifactFileNames] | 

try:
    # Submits a job. This call is primarily intended to be used by the Flink client. This call expects a multipart/form-data request that consists of file uploads for the serialized JobGraph, jars and distributed cache artifacts and an attribute named \"request\" for the JSON payload
    api_response = api_instance.submit_job(job_graph_file_name, job_jar_file_names, job_artifact_file_names)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->submit_job: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
mode = 'mode_example' # str | String value that specifies the termination mode. Supported values are: \"cancel, stop\" (optional)

try:
    # Terminates a job
    api_instance.terminate_job(jobid, mode=mode)
except ApiException as e:
    print("Exception when calling FlinkApi->terminate_job: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jobid = 'jobid_example' # str | 32-character hexadecimal string value that identifies a job
parallelism = 56 # int | Positive integer value that specifies the desired parallelism

try:
    # Triggers the rescaling of a job
    api_response = api_instance.trigger_job_rescaling(jobid, parallelism)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->trigger_job_rescaling: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
body = swagger_client.SavepointDisposalRequest() # SavepointDisposalRequest | 

try:
    # Triggers the desposal of a savepoint
    api_response = api_instance.trigger_savepoint_disposal(body)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->trigger_savepoint_disposal: %s\n" % e)

# create an instance of the API class
api_instance = swagger_client.FlinkApi(swagger_client.ApiClient(configuration))
jarfile = 'jarfile_example' # str | 

try:
    # Uploads a jar to the cluster
    api_response = api_instance.upload_jar(jarfile)
    pprint(api_response)
except ApiException as e:
    print("Exception when calling FlinkApi->upload_jar: %s\n" % e)
```

## Documentation for API Endpoints

All URIs are relative to */*

Class | Method | HTTP request | Description
------------ | ------------- | ------------- | -------------
*FlinkApi* | [**create_job_savepoint**](docs/FlinkApi.md#create_job_savepoint) | **POST** /jobs/{jobid}/savepoints | Triggers a savepoint, and optionally cancels the job afterwards
*FlinkApi* | [**delete_jar**](docs/FlinkApi.md#delete_jar) | **DELETE** /jars/{jarid} | Deletes a jar previously uploaded via &#x27;/jars/upload&#x27;
*FlinkApi* | [**get_job_accumulators**](docs/FlinkApi.md#get_job_accumulators) | **GET** /jobs/{jobid}/accumulators | Returns the accumulators for all tasks of a job, aggregated across the respective subtasks
*FlinkApi* | [**get_job_aggregated_subtask_metrics**](docs/FlinkApi.md#get_job_aggregated_subtask_metrics) | **GET** /jobs/{jobid}/vertices/{vertexid}/subtasks/metrics | Provides access to aggregated subtask metrics
*FlinkApi* | [**get_job_checkpoint_details**](docs/FlinkApi.md#get_job_checkpoint_details) | **GET** /jobs/{jobid}/checkpoints/details/{checkpointid} | Returns details for a checkpoint
*FlinkApi* | [**get_job_checkpoint_statistics**](docs/FlinkApi.md#get_job_checkpoint_statistics) | **GET** /jobs/{jobid}/checkpoints/details/{checkpointid}/subtasks/{vertexid} | Returns checkpoint statistics for a task and its subtasks
*FlinkApi* | [**get_job_checkpoints**](docs/FlinkApi.md#get_job_checkpoints) | **GET** /jobs/{jobid}/checkpoints | Returns checkpointing statistics for a job
*FlinkApi* | [**get_job_checkpoints_config**](docs/FlinkApi.md#get_job_checkpoints_config) | **GET** /jobs/{jobid}/checkpoints/config | Returns the checkpointing configuration
*FlinkApi* | [**get_job_config**](docs/FlinkApi.md#get_job_config) | **GET** /jobs/{jobid}/config | Returns the configuration of a job
*FlinkApi* | [**get_job_details**](docs/FlinkApi.md#get_job_details) | **GET** /jobs/{jobid} | Returns details of a job
*FlinkApi* | [**get_job_exceptions**](docs/FlinkApi.md#get_job_exceptions) | **GET** /jobs/{jobid}/exceptions | Returns the non-recoverable exceptions that have been observed by the job. The truncated flag defines whether more exceptions occurred, but are not listed, because the response would otherwise get too big
*FlinkApi* | [**get_job_manager_metrics**](docs/FlinkApi.md#get_job_manager_metrics) | **GET** /jobmanager/metrics | Provides access to job manager metrics
*FlinkApi* | [**get_job_metrics**](docs/FlinkApi.md#get_job_metrics) | **GET** /jobs/{jobid}/metrics | Provides access to job metrics
*FlinkApi* | [**get_job_plan**](docs/FlinkApi.md#get_job_plan) | **GET** /jobs/{jobid}/plan | Returns the dataflow plan of a job
*FlinkApi* | [**get_job_rescaling_status**](docs/FlinkApi.md#get_job_rescaling_status) | **GET** /jobs/{jobid}/rescaling/{triggerid} | Returns the status of a rescaling operation
*FlinkApi* | [**get_job_result**](docs/FlinkApi.md#get_job_result) | **GET** /jobs/{jobid}/execution-result | Returns the result of a job execution. Gives access to the execution time of the job and to all accumulators created by this job
*FlinkApi* | [**get_job_savepoint_status**](docs/FlinkApi.md#get_job_savepoint_status) | **GET** /jobs/{jobid}/savepoints/{triggerid} | Returns the status of a savepoint operation
*FlinkApi* | [**get_job_subtask_accumulators**](docs/FlinkApi.md#get_job_subtask_accumulators) | **GET** /jobs/{jobid}/vertices/{vertexid}/subtasks/accumulators | Returns all user-defined accumulators for all subtasks of a task
*FlinkApi* | [**get_job_subtask_attempt_accumulators**](docs/FlinkApi.md#get_job_subtask_attempt_accumulators) | **GET** /jobs/{jobid}/vertices/{vertexid}/subtasks/{subtaskindex}/attempts/:attempt/accumulators | Returns the accumulators of an execution attempt of a subtask. Multiple execution attempts happen in case of failure/recovery
*FlinkApi* | [**get_job_subtask_attempt_details**](docs/FlinkApi.md#get_job_subtask_attempt_details) | **GET** /jobs/{jobid}/vertices/{vertexid}/subtasks/{subtaskindex}/attempts/:attempt | Returns details of an execution attempt of a subtask. Multiple execution attempts happen in case of failure/recovery
*FlinkApi* | [**get_job_subtask_details**](docs/FlinkApi.md#get_job_subtask_details) | **GET** /jobs/{jobid}/vertices/{vertexid}/subtasks/{subtaskindex} | Returns details of the current or latest execution attempt of a subtask
*FlinkApi* | [**get_job_subtask_metrics**](docs/FlinkApi.md#get_job_subtask_metrics) | **GET** /jobs/{jobid}/vertices/{vertexid}/subtasks/{subtaskindex}/metrics | Provides access to subtask metrics
*FlinkApi* | [**get_job_subtask_times**](docs/FlinkApi.md#get_job_subtask_times) | **GET** /jobs/{jobid}/vertices/{vertexid}/subtasktimes | Returns time-related information for all subtasks of a task
*FlinkApi* | [**get_job_task_accumulators**](docs/FlinkApi.md#get_job_task_accumulators) | **GET** /jobs/{jobid}/vertices/{vertexid}/accumulators | Returns user-defined accumulators of a task, aggregated across all subtasks
*FlinkApi* | [**get_job_task_backpressure**](docs/FlinkApi.md#get_job_task_backpressure) | **GET** /jobs/{jobid}/vertices/{vertexid}/backpressure | Returns back-pressure information for a job, and may initiate back-pressure sampling if necessary
*FlinkApi* | [**get_job_task_details**](docs/FlinkApi.md#get_job_task_details) | **GET** /jobs/{jobid}/vertices/{vertexid} | Returns details for a task, with a summary for each of its subtasks
*FlinkApi* | [**get_job_task_details_by_task_manager**](docs/FlinkApi.md#get_job_task_details_by_task_manager) | **GET** /jobs/{jobid}/vertices/{vertexid}/taskmanagers | Returns task information aggregated by task manager
*FlinkApi* | [**get_job_task_metrics**](docs/FlinkApi.md#get_job_task_metrics) | **GET** /jobs/{jobid}/vertices/{vertexid}/metrics | Provides access to task metrics
*FlinkApi* | [**get_jobs**](docs/FlinkApi.md#get_jobs) | **GET** /jobs | Returns an overview over all jobs and their current state
*FlinkApi* | [**get_jobs_metrics**](docs/FlinkApi.md#get_jobs_metrics) | **GET** /jobs/metrics | Provides access to aggregated job metrics
*FlinkApi* | [**get_jobs_overview**](docs/FlinkApi.md#get_jobs_overview) | **GET** /jobs/overview | Returns an overview over all jobs
*FlinkApi* | [**get_overview**](docs/FlinkApi.md#get_overview) | **GET** /overview | Returns an overview over the Flink cluster
*FlinkApi* | [**get_savepoint_disposal_status**](docs/FlinkApi.md#get_savepoint_disposal_status) | **GET** /savepoint-disposal/{triggerid} | Returns the status of a savepoint disposal operation
*FlinkApi* | [**get_task_manager_aggregated_metrics**](docs/FlinkApi.md#get_task_manager_aggregated_metrics) | **GET** /taskmanagers/metrics | Provides access to aggregated task manager metrics
*FlinkApi* | [**get_task_manager_details**](docs/FlinkApi.md#get_task_manager_details) | **GET** /taskmanagers/{taskmanagerid} | Returns details for a task manager
*FlinkApi* | [**get_task_manager_metrics**](docs/FlinkApi.md#get_task_manager_metrics) | **GET** /taskmanagers/{taskmanagerid}/metrics | Provides access to task manager metrics
*FlinkApi* | [**get_task_managers_overview**](docs/FlinkApi.md#get_task_managers_overview) | **GET** /taskmanagers | Returns an overview over all task managers
*FlinkApi* | [**list_jars**](docs/FlinkApi.md#list_jars) | **GET** /jars | Returns a list of all jars previously uploaded via &#x27;/jars/upload&#x27;
*FlinkApi* | [**run_jar**](docs/FlinkApi.md#run_jar) | **POST** /jars/{jarid}/run | Submits a job by running a jar previously uploaded via &#x27;/jars/upload&#x27;. Program arguments can be passed both via the JSON request (recommended) or query parameters
*FlinkApi* | [**show_config**](docs/FlinkApi.md#show_config) | **GET** /config | Returns the configuration of the WebUI
*FlinkApi* | [**show_job_manager_config**](docs/FlinkApi.md#show_job_manager_config) | **GET** /jobmanager/config | Returns the cluster configuration
*FlinkApi* | [**show_plan**](docs/FlinkApi.md#show_plan) | **GET** /jars/{jarid}/plan | Returns the dataflow plan of a job contained in a jar previously uploaded via &#x27;/jars/upload&#x27;. Program arguments can be passed both via the JSON request (recommended) or query parameters
*FlinkApi* | [**shutdown_cluster**](docs/FlinkApi.md#shutdown_cluster) | **DELETE** /cluster | Shuts-down the cluster
*FlinkApi* | [**submit_job**](docs/FlinkApi.md#submit_job) | **POST** /jobs | Submits a job. This call is primarily intended to be used by the Flink client. This call expects a multipart/form-data request that consists of file uploads for the serialized JobGraph, jars and distributed cache artifacts and an attribute named \&quot;request\&quot; for the JSON payload
*FlinkApi* | [**terminate_job**](docs/FlinkApi.md#terminate_job) | **PATCH** /jobs/{jobid} | Terminates a job
*FlinkApi* | [**trigger_job_rescaling**](docs/FlinkApi.md#trigger_job_rescaling) | **PATCH** /jobs/{jobid}/rescaling | Triggers the rescaling of a job
*FlinkApi* | [**trigger_savepoint_disposal**](docs/FlinkApi.md#trigger_savepoint_disposal) | **POST** /savepoint-disposal | Triggers the desposal of a savepoint
*FlinkApi* | [**upload_jar**](docs/FlinkApi.md#upload_jar) | **POST** /jars/upload | Uploads a jar to the cluster

## Documentation For Models

 - [AsynchronousOperationResult](docs/AsynchronousOperationResult.md)
 - [Body](docs/Body.md)
 - [Body1](docs/Body1.md)
 - [CheckpointConfigInfo](docs/CheckpointConfigInfo.md)
 - [CheckpointStatistics](docs/CheckpointStatistics.md)
 - [CheckpointingStatistics](docs/CheckpointingStatistics.md)
 - [CheckpointingStatisticsCounts](docs/CheckpointingStatisticsCounts.md)
 - [CheckpointingStatisticsLatestCheckpoints](docs/CheckpointingStatisticsLatestCheckpoints.md)
 - [CheckpointingStatisticsSummary](docs/CheckpointingStatisticsSummary.md)
 - [ClusterConfigurationInfoEntry](docs/ClusterConfigurationInfoEntry.md)
 - [ClusterOverviewWithVersion](docs/ClusterOverviewWithVersion.md)
 - [CompletedCheckpointStatistics](docs/CompletedCheckpointStatistics.md)
 - [DashboardConfiguration](docs/DashboardConfiguration.md)
 - [DistributedCacheFile](docs/DistributedCacheFile.md)
 - [ExecutionExceptionInfo](docs/ExecutionExceptionInfo.md)
 - [ExternalizedCheckpointInfo](docs/ExternalizedCheckpointInfo.md)
 - [FailedCheckpointStatistics](docs/FailedCheckpointStatistics.md)
 - [GarbageCollectorInfo](docs/GarbageCollectorInfo.md)
 - [HardwareDescription](docs/HardwareDescription.md)
 - [IOMetricsInfo](docs/IOMetricsInfo.md)
 - [JarEntryInfo](docs/JarEntryInfo.md)
 - [JarFileInfo](docs/JarFileInfo.md)
 - [JarListInfo](docs/JarListInfo.md)
 - [JarPlanRequestBody](docs/JarPlanRequestBody.md)
 - [JarRunRequestBody](docs/JarRunRequestBody.md)
 - [JarRunResponseBody](docs/JarRunResponseBody.md)
 - [JarUploadResponseBody](docs/JarUploadResponseBody.md)
 - [JobAccumulatorsInfo](docs/JobAccumulatorsInfo.md)
 - [JobDetailsInfo](docs/JobDetailsInfo.md)
 - [JobDetailsInfoJobPlan](docs/JobDetailsInfoJobPlan.md)
 - [JobDetailsInfoJobVertexDetailsInfo](docs/JobDetailsInfoJobVertexDetailsInfo.md)
 - [JobDetailsInfoNode](docs/JobDetailsInfoNode.md)
 - [JobExceptionsInfo](docs/JobExceptionsInfo.md)
 - [JobExecutionResultResponseBody](docs/JobExecutionResultResponseBody.md)
 - [JobIdWithStatus](docs/JobIdWithStatus.md)
 - [JobIdsWithStatusOverview](docs/JobIdsWithStatusOverview.md)
 - [JobPlanInfo](docs/JobPlanInfo.md)
 - [JobSubmitRequestBody](docs/JobSubmitRequestBody.md)
 - [JobSubmitResponseBody](docs/JobSubmitResponseBody.md)
 - [JobVertexAccumulatorsInfo](docs/JobVertexAccumulatorsInfo.md)
 - [JobVertexBackPressureInfo](docs/JobVertexBackPressureInfo.md)
 - [JobVertexDetailsInfo](docs/JobVertexDetailsInfo.md)
 - [JobVertexTaskManagersInfo](docs/JobVertexTaskManagersInfo.md)
 - [JobVertexTaskManagersInfoTaskManagersInfo](docs/JobVertexTaskManagersInfoTaskManagersInfo.md)
 - [JobsJobArtifactFileNames](docs/JobsJobArtifactFileNames.md)
 - [MinMaxAvgStatistics](docs/MinMaxAvgStatistics.md)
 - [MultipleJobsDetails](docs/MultipleJobsDetails.md)
 - [QueueStatus](docs/QueueStatus.md)
 - [RestoredCheckpointStatistics](docs/RestoredCheckpointStatistics.md)
 - [SavepointDisposalRequest](docs/SavepointDisposalRequest.md)
 - [SavepointTriggerRequestBody](docs/SavepointTriggerRequestBody.md)
 - [SubtaskAccumulatorsInfo](docs/SubtaskAccumulatorsInfo.md)
 - [SubtaskBackPressureInfo](docs/SubtaskBackPressureInfo.md)
 - [SubtaskCheckpointStatistics](docs/SubtaskCheckpointStatistics.md)
 - [SubtaskExecutionAttemptAccumulatorsInfo](docs/SubtaskExecutionAttemptAccumulatorsInfo.md)
 - [SubtaskExecutionAttemptDetailsInfo](docs/SubtaskExecutionAttemptDetailsInfo.md)
 - [SubtaskTimeInfo](docs/SubtaskTimeInfo.md)
 - [SubtasksAllAccumulatorsInfo](docs/SubtasksAllAccumulatorsInfo.md)
 - [SubtasksTimesInfo](docs/SubtasksTimesInfo.md)
 - [TaskCheckpointStatistics](docs/TaskCheckpointStatistics.md)
 - [TaskCheckpointStatisticsWithSubtaskDetails](docs/TaskCheckpointStatisticsWithSubtaskDetails.md)
 - [TaskCheckpointStatisticsWithSubtaskDetailsCheckpointAlignment](docs/TaskCheckpointStatisticsWithSubtaskDetailsCheckpointAlignment.md)
 - [TaskCheckpointStatisticsWithSubtaskDetailsCheckpointDuration](docs/TaskCheckpointStatisticsWithSubtaskDetailsCheckpointDuration.md)
 - [TaskCheckpointStatisticsWithSubtaskDetailsSummary](docs/TaskCheckpointStatisticsWithSubtaskDetailsSummary.md)
 - [TaskManagerDetailsInfo](docs/TaskManagerDetailsInfo.md)
 - [TaskManagerInfo](docs/TaskManagerInfo.md)
 - [TaskManagerMetricsInfo](docs/TaskManagerMetricsInfo.md)
 - [TaskManagersInfo](docs/TaskManagersInfo.md)
 - [TriggerResponse](docs/TriggerResponse.md)
 - [UserAccumulator](docs/UserAccumulator.md)
 - [UserTaskAccumulator](docs/UserTaskAccumulator.md)
 - [VertexTaskDetail](docs/VertexTaskDetail.md)

## Documentation For Authorization

 All endpoints do not require authorization.


## Author


